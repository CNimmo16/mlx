{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINI MODE: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcameronnimmo\u001b[0m (\u001b[33mcnimmo16\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/cameron/Documents/mlx/hackernews/wandb/run-20250130_121602-yyegukd8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cnimmo16/word2vec/runs/yyegukd8' target=\"_blank\">pleasant-bee-64</a></strong> to <a href='https://wandb.ai/cnimmo16/word2vec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cnimmo16/word2vec' target=\"_blank\">https://wandb.ai/cnimmo16/word2vec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cnimmo16/word2vec/runs/yyegukd8' target=\"_blank\">https://wandb.ai/cnimmo16/word2vec/runs/yyegukd8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import skipgram\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"word2vec\")\n",
    "artifact = run.use_artifact(\"model-weights:latest\")\n",
    "datadir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'embeddings.weight': tensor([[ 1.9269,  1.4873,  0.9007,  ..., -0.4879, -0.9138, -0.6581],\n",
      "        [ 0.0780,  0.5258, -0.4880,  ...,  0.4880,  0.7846,  0.0286],\n",
      "        [ 0.7921,  0.7724,  1.2230,  ...,  1.6339,  0.4167, -0.3995],\n",
      "        ...,\n",
      "        [-0.6330,  0.1846, -0.8211,  ...,  0.2991,  0.7049,  0.8997],\n",
      "        [-0.9033, -1.2141, -0.7326,  ..., -1.3640,  0.3009,  0.7943],\n",
      "        [-1.0489, -0.5225, -1.1338,  ...,  0.8321,  0.9070,  0.0391]]), 'linear.weight': tensor([[-0.0882,  0.0111, -0.0100,  ..., -0.0461, -0.0593, -0.0729],\n",
      "        [ 0.2270,  0.0895,  0.2126,  ...,  0.2022,  0.1374, -0.0352],\n",
      "        [-0.0056,  0.1953,  0.2204,  ...,  0.0697,  0.0889,  0.0642],\n",
      "        ...,\n",
      "        [-0.2915, -0.0183,  0.1372,  ...,  0.0169,  0.0151,  0.1846],\n",
      "        [ 0.0025,  0.2679, -0.0650,  ...,  0.2539,  0.0110,  0.0057],\n",
      "        [-0.2341, -0.0694, -0.2223,  ..., -0.0881,  0.0627,  0.0505]]), 'linear.bias': tensor([ 0.0992, -0.0737, -0.0629,  0.1086,  0.0553, -0.0804,  0.0428,  0.0713,\n",
      "        -0.1256,  0.0264,  0.0323, -0.0055,  0.1356, -0.0935,  0.0767, -0.0751,\n",
      "        -0.1211,  0.0964, -0.0678,  0.0066,  0.0744, -0.1180, -0.1211,  0.0481,\n",
      "         0.1233, -0.0150,  0.0996,  0.0497])})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = skipgram.Model(vocab.size + 1, skipgram.EMBEDDING_DIM)\n",
    "\n",
    "state_dict = torch.load('./data/weights.generated.pt')\n",
    "# model.load_state_dict(weights)\n",
    "# model.eval()\n",
    "\n",
    "print(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ml', 0.38398277759552),\n",
       " ('decisions', 0.3758777678012848),\n",
       " ('models', 0.19850623607635498),\n",
       " ('improve', 0.13952332735061646),\n",
       " ('unk', 0.10921022295951843)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = pd.read_csv(f\"data/vocab{'__mini' if skipgram.MINIMODE else ''}.generated.csv\", index_col='token')\n",
    "\n",
    "def getIdFromToken(token: str):\n",
    "    try:\n",
    "        return int(vocab.at[token, 'id'])\n",
    "    except:\n",
    "        return int(vocab.at['unk', 'id'])\n",
    "\n",
    "#find the n most similar words\n",
    "def most_similar(word, n=5):\n",
    "    word_idx = getIdFromToken(word)\n",
    "    A =  state_dict['embeddings.weight'][word_idx].unsqueeze(0)\n",
    "    word_similarities = []\n",
    "    for token, ids in vocab.iterrows():\n",
    "        id = ids.values[0]\n",
    "        B =  model.embeddings.weight[id].unsqueeze(0)\n",
    "        cosine_similarity = torch.nn.functional.cosine_similarity(A, B, dim=1)\n",
    "        word_similarities.append((token, cosine_similarity.item()))\n",
    "    word_similarities = sorted(word_similarities, key=lambda x: x[1], reverse=True)\n",
    "    return word_similarities[:n]\n",
    "\n",
    "most_similar('ml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-8wZyJbLr-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
