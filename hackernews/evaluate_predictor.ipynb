{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.artifacts' from '/Users/cameron/Documents/mlx/hackernews/util/artifacts.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models import upvote_predictor, skipgram\n",
    "import pandas as pd\n",
    "import os\n",
    "from util import artifacts, cache\n",
    "import tokenization\n",
    "import embeddings\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "importlib.reload(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predictor-state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_artifacts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictor-state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m vocab \u001b[38;5;241m=\u001b[39m loaded_artifacts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m upvote_predictor\u001b[38;5;241m.\u001b[39mModel(skipgram\u001b[38;5;241m.\u001b[39mEMBEDDING_DIM)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predictor-state'"
     ]
    }
   ],
   "source": [
    "state_dict = artifacts.load_artifact('predictor-state')\n",
    "vocab = artifacts.load_artifact('vocab')\n",
    "embed_scaler = artifacts.load_artifact('predictor-embed-scaler')\n",
    "karma_scaler = artifacts.load_artifact('predictor-karma-scaler')\n",
    "\n",
    "model = upvote_predictor.Model(skipgram.EMBEDDING_DIM)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=19 sec). Create a new API with an integer timeout larger than 19, e.g., `api = wandb.Api(timeout=29)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'embed-scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m hn_test_posts\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     20\u001b[0m artifacts \u001b[38;5;241m=\u001b[39m artifacts\u001b[38;5;241m.\u001b[39mload_artifacts()\n\u001b[0;32m---> 22\u001b[0m embed_scaler \u001b[38;5;241m=\u001b[39m \u001b[43martifacts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membed-scaler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m karma_scaler \u001b[38;5;241m=\u001b[39m artifacts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkarma-scaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m title_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(np\u001b[38;5;241m.\u001b[39marray(hn_test_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embed-scaler'"
     ]
    }
   ],
   "source": [
    "items_table = \"hacker_news.items\"\n",
    "\n",
    "hn_test_posts = cache.query(\"hn_posts_for_test\", f\"\"\"SELECT\n",
    "    title,\n",
    "    karma,\n",
    "    score\n",
    "    FROM {items_table}\n",
    "    INNER JOIN hacker_news.users u ON {items_table}.by = u.id\n",
    "    WHERE type = 'story' AND title IS NOT null\n",
    "    OFFSET 1000000\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "hn_test_posts.dropna(inplace=True)\n",
    "\n",
    "hn_test_posts['embeddings'] = hn_test_posts['title'].apply(embeddings.get_embeddings_for_title)\n",
    "\n",
    "hn_test_posts.dropna()\n",
    "\n",
    "title_embeddings = np.vstack(np.array(hn_test_posts['embeddings'].values))\n",
    "title_embeddings = embed_scaler.transform(title_embeddings)\n",
    "\n",
    "karma = hn_test_posts['karma'].values.reshape(-1, 1)\n",
    "karma = karma_scaler.transform(karma)\n",
    "\n",
    "def eval_test_row(row):\n",
    "    embeddings = row['embeddings']\n",
    "    karma = row['karma']\n",
    "    return model(embeddings, karma)\n",
    "\n",
    "hn_test_posts['predicted_score'] = hn_test_posts.apply(eval_test_row)\n",
    "hn_test_posts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-8wZyJbLr-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
